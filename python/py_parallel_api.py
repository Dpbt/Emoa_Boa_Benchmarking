"""
About: Python helper APIs for running algorithms and processing results from tests.
Author: Zhongqiang (Richard) Ren and Denis Derkach
"""

import random
import numpy as np
import subprocess
import pandas as pd
from tqdm import tqdm
from joblib import Parallel, delayed

from python.tests_generator import ny_tests_generator, simple_map_tests_generator

# ATTENTION: Constants for file paths, change it if needed
BASH_PATH = "C:\\Program Files\\Git\\bin\\bash.exe"
BASE_EXECUTABLE_PATH = "C:/Users/denis/CLionProjects/Emoa_heu/cmake-build-debug/"
RESULTS_PATH = "../data_out/technical_txts/simple_map_{}.txt"


def getResult(res_file: str) -> dict:
    """
    Parses the result file and extracts relevant metrics into a dictionary.

    :param res_file: Path to the result file generated by the algorithm.
    :return: A dictionary containing extracted metrics such as number of generated nodes,
             expanded nodes, search times, and solution paths.
    """
    res_dict = dict()
    with open(res_file, mode="r") as fres:
        lines = fres.readlines()
        res_dict["n_generated"] = int(lines[1].split(":")[1])
        res_dict["n_expanded"] = int(lines[2].split(":")[1])
        res_dict["n_domCheck"] = int(lines[3].split(":")[1])
        res_dict["rt_initHeu"] = float(lines[4].split(":")[1])
        res_dict["rt_search"] = float(lines[5].split(":")[1])
        res_dict["timeout"] = int(lines[6].split(":")[1])
        res_dict["num_nondom_labels_max"] = float(lines[7].split(":")[1])
        res_dict["num_nondom_labels_avg"] = float(lines[8].split(":")[1])
        res_dict["num_solutions"] = int(lines[9].split(":")[1])

        start_idx = 10
        res_dict["paths"] = dict()
        res_dict["costs"] = dict()

        for i in range(res_dict["num_solutions"]):
            # Solution ID
            solID = int(lines[start_idx + 3 * i].split(":")[1])
            # Cost vector
            cvec = [int(float(x)) for x in lines[start_idx + 3 * i + 1].strip().split(",")[1:-1]]
            res_dict["costs"][solID] = np.array(cvec)
            # Path
            res_dict["paths"][solID] = list(map(int, lines[start_idx + 3 * i + 2].strip().split()[:-1]))

    return res_dict


def run_algorithm(cg_list: list, exe_path: str, res_path: str, vo: int, vd: int, tlimit: int) -> dict:
    """
    Runs the specified algorithm using subprocess and retrieves results.

    ATTENTION: Constants for file paths are in the beginning of file, you probably need to change them.

    :param cg_list: List of command-line arguments for the algorithm.
    :param exe_path: Path to the executable file of the algorithm.
    :param res_path: Path where results will be saved.
    :param vo: Starting vertex index.
    :param vd: Destination vertex index.
    :param tlimit: Time limit for the algorithm execution.
    :return: A dictionary containing results from the algorithm execution.
    """
    cmd = [str(vo), str(vd), str(tlimit), str(len(cg_list))] + cg_list + [res_path]

    cmd_s = " ".join(cmd)

    cmd = [BASH_PATH, "-c", f"{BASE_EXECUTABLE_PATH}{exe_path} {cmd_s}"]

    process = subprocess.Popen(cmd, stdout=subprocess.PIPE)
    process.wait()

    out = getResult(res_path)

    return out


def test_system(tests: list, display_progress: bool = False) -> pd.DataFrame:
    """
    Executes a series of tests on specified algorithms and collects results.

    :param tests: A list of test parameters including algorithm type and configurations.
    :param display_progress: If True, displays a progress bar during execution.
    :return: A DataFrame containing results of all tests executed.
    """

    exp_num = 0
    test_results = pd.DataFrame(columns=["test_number", "algorithm", "map_name", "num_dims",
                                         "heuristic_time", "search_time", "num_solutions", "time_limit",
                                         "start", "goal", "n_generated", "n_expanded",
                                         "timeout", "num_nondom_labels_max", "num_nondom_labels_avg"])

    iterator = tqdm(tests, desc="Running tests") if display_progress else tests

    for test in iterator:
        exp_num += 1

        test_number, algorithm, map_name, time_limit, start, goal, result_file, maps = test

        exe_path = "run_emoa.exe" if algorithm == "emoa" else "run_boalex.exe"

        out = run_algorithm(cg_list=maps,
                            exe_path=exe_path,
                            res_path=result_file,
                            vo=start,
                            vd=goal,
                            tlimit=time_limit)

        new_row = {
            "test_number": test_number,
            "algorithm": algorithm,
            "map_name": map_name,
            "num_dims": len(maps),
            "time_limit": time_limit,
            "start": start,
            "goal": goal,
            "n_generated": out["n_generated"],
            "n_expanded": out["n_expanded"],
            "heuristic_time": out["rt_initHeu"],
            "search_time": out["rt_search"],
            "timeout": out["timeout"],
            "num_nondom_labels_max": out["num_nondom_labels_max"],
            "num_nondom_labels_avg": out["num_nondom_labels_avg"],
            "num_solutions": out["num_solutions"]
        }

        test_results = pd.concat([test_results, pd.DataFrame([new_row])], ignore_index=True)

    return test_results


def parallel_run(tests: list, batch_size: int = 1, n_jobs: int = 1, display_progress: bool = False) -> pd.DataFrame:
    """
    Executes tests in parallel using joblib.

    :param tests: A list of test parameters including algorithm type and configurations.
    :param batch_size: Number of tests to run in each batch.
    :param n_jobs: Number of parallel jobs to run.
    :param display_progress: If True, displays a progress bar during execution. Works correctly only when n_jobs=1.
    :return: A DataFrame containing results of all tests executed.
    """

    random.shuffle(tests)

    for i in range(len(tests)):
        tests[i] = tests[i][:6] + [f"../data_out/technical_txts/technical_{i % (n_jobs * 2)}.txt"] + [tests[i][6]]

    num_batch = (len(tests) // batch_size) + (len(tests) % batch_size > 0)

    tests_with_batch = [tests[i * batch_size:(i + 1) * batch_size] for i in range(num_batch)]

    with Parallel(n_jobs=n_jobs, verbose=11, backend="threading") as parallel:
        results = parallel(
            delayed(test_system)(test_batch, display_progress=display_progress) for test_batch in tests_with_batch)

    test_results = pd.concat(results, ignore_index=True)

    return test_results


if __name__ == "__main__":
    random.seed(20)
    np.random.seed(20)
    pd.set_option("display.max_columns", None)

    # Example of usage. You can read how the test lists are generated in the README.
    tests = [[1, "emoa", "example map 3 dims", 600, 1, 5,
              ["../data/ex1-c1.gr", "../data/ex1-c2.gr", "../data/ex1-c3.gr"]],
             [1, "boa", "example map 3 dims", 600, 1, 5,
              ["../data/ex1-c1.gr", "../data/ex1-c2.gr", "../data/ex1-c3.gr"]]
             ]

    test_results = parallel_run(tests, batch_size=1, n_jobs=2, display_progress=False)
    test_results.to_csv("../data_out/example_results/example_map.csv", index=False)
    print(test_results)

    # NY tests: can be uncommented if needed
    # tests = ny_tests_generator(num_tests=100)
    # tests = tests[150:200]
    # test_results = parallel_run(tests, batch_size=1, n_jobs=5, display_progress=False)
    # test_results.to_csv("../data_out/NY_results/NY_test_results_2_2.csv", index=False)
    # print(test_results)

    # Simple maps tests: can be uncommented if needed
    # tests_params = [
    #     {"num_dims": 3, "width": 30, "height": 30},
    #     {"num_dims": 4, "width": 15, "height": 15},
    #     {"num_dims": 5, "width": 12, "height": 12},
    #     {"num_dims": 6, "width": 10, "height": 10},
    #     {"num_dims": 7, "width": 9, "height": 9},
    #     {"num_dims": 8, "width": 9, "height": 9},
    #     {"num_dims": 9, "width": 8, "height": 8},
    #     {"num_dims": 10, "width": 8, "height": 8},
    # ]
    #
    # for test in tests_params:
    #     for walls_ratio in [0.0, 0.05, 0.10]:
    #         num_dims = test["num_dims"]
    #         width = test["width"]
    #         height = test["height"]
    #         walls_percent = int(walls_ratio * 100)
    #
    #         tests = simple_map_tests_generator(num_tests=50,
    #                                            start=1,
    #                                            finish=width * height,
    #                                            width=width,
    #                                            height=height,
    #                                            num_dims=num_dims,
    #                                            walls=True if walls_percent > 0 else False,
    #                                            walls_ratio=walls_ratio,
    #                                            map_name_local="simple_map",
    #                                            time_limit=600)
    #
    #         test_results = parallel_run(tests, batch_size=1, n_jobs=4, display_progress=False)
    #         test_results.to_csv(f"../data_out/simple_map_{num_dims}_results/simple_map_{num_dims}_{walls_percent}.csv", index=False)
    #         print(test_results)
